{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWjxZGxfJDRm"
      },
      "source": [
        "## **IMPORT LIBRARY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-9Cxr9DItQ5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # Untuk manipulasi Data\n",
        "import numpy as np # Untuk operasi matematika dan array multidimensi\n",
        "from sklearn.preprocessing import StandardScaler # Untuk melakukan penskalaan fitur\n",
        "from sklearn.model_selection import train_test_split # Untuk membagi dataset menjadi set pelatihan dan pengujian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvR4-49ZKsnU"
      },
      "source": [
        "## **IMPORT DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ffR_gC-JK6Y"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/Churn_Modelling.csv\") #Baca Data CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "VyM2tOCCJTr1",
        "outputId": "3e6d9d6c-53e1-4738-dfd1-9846d5fda560"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"RowNumber\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2886,\n        \"min\": 1,\n        \"max\": 10000,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          6253,\n          4685,\n          1732\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CustomerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71936,\n        \"min\": 15565701,\n        \"max\": 15815690,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          15687492,\n          15736963,\n          15721730\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Surname\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2932,\n        \"samples\": [\n          \"McGuirk\",\n          \"Torkelson\",\n          \"Rapuluchukwu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CreditScore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96,\n        \"min\": 350,\n        \"max\": 850,\n        \"num_unique_values\": 460,\n        \"samples\": [\n          754,\n          533,\n          744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Geography\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"France\",\n          \"Spain\",\n          \"Germany\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 18,\n        \"max\": 92,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          61,\n          42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tenure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          6,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62397.405202385955,\n        \"min\": 0.0,\n        \"max\": 250898.09,\n        \"num_unique_values\": 6382,\n        \"samples\": [\n          117707.18,\n          133050.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumOfProducts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HasCrCard\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsActiveMember\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EstimatedSalary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57510.49281769816,\n        \"min\": 11.58,\n        \"max\": 199992.48,\n        \"num_unique_values\": 9999,\n        \"samples\": [\n          100809.99,\n          95273.73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Exited\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-fbb0adf5-8fe8-4aa8-ba29-0d3b892a213b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbb0adf5-8fe8-4aa8-ba29-0d3b892a213b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fbb0adf5-8fe8-4aa8-ba29-0d3b892a213b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fbb0adf5-8fe8-4aa8-ba29-0d3b892a213b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa44c5ae-0427-4b00-94ef-738a51aa050f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa44c5ae-0427-4b00-94ef-738a51aa050f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa44c5ae-0427-4b00-94ef-738a51aa050f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head() #Tampilkan Data Awal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZUl7Qq7HNGA"
      },
      "source": [
        "## **DATA EXPLORATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o63ImqgqljNL"
      },
      "source": [
        "### CHECK MISSING VALUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9UboWuaJXR6",
        "outputId": "55581e50-8b51-4719-e886-8b875deae73d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RowNumber          False\n",
            "CustomerId         False\n",
            "Surname            False\n",
            "CreditScore        False\n",
            "Geography          False\n",
            "Gender             False\n",
            "Age                False\n",
            "Tenure             False\n",
            "Balance            False\n",
            "NumOfProducts      False\n",
            "HasCrCard          False\n",
            "IsActiveMember     False\n",
            "EstimatedSalary    False\n",
            "Exited             False\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "print(data.isnull().any()) # Cek Data Kosong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfQXjwuRmEFc"
      },
      "source": [
        "* Tidak ada missing value terhadap data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LogX2kdlsve"
      },
      "source": [
        "### CHECK DATA TYPES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc6AM9B4JcUf",
        "outputId": "3563989d-aa1d-42fc-9631-58a62f0a4b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info() #Info Data Frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5bEgHm6nQvp"
      },
      "source": [
        "### CHECK UNIQUE VALUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Nh7aJZJgDu",
        "outputId": "a2278214-09cf-4d99-8c38-977ea4494311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Hargrave' 'Hill' 'Onio' ... 'Kashiwagi' 'Aldridge' 'Burbidge']\n",
            "['France' 'Spain' 'Germany']\n",
            "['Female' 'Male']\n"
          ]
        }
      ],
      "source": [
        "print(data['Surname'].unique()) #Unik Surname\n",
        "print(data['Geography'].unique()) #Unik Geography\n",
        "print(data['Gender'].unique()) #Unik Gender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTxwwIZ-uzzz"
      },
      "source": [
        "## **DUMMY VARIABLE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHUGrf6zJjDe"
      },
      "outputs": [],
      "source": [
        "data = pd.get_dummies(data, columns=['Geography', 'Gender', 'Surname'], drop_first=True) # Mengubah variabel kategorik menjadi dummy variabel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55r28Dl3L7TG"
      },
      "source": [
        "## **NORMALISASI DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3us_TuiJmuu"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler() # Melakukan penskalaan fitur\n",
        "numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "data[numerical_features] = scaler.fit_transform(data[numerical_features])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjnOwImNNJ5R"
      },
      "source": [
        "## **SPLIT DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYPOy203Durc"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan X dan Y\n",
        "X = data.drop('Exited', axis=1) # Drop variabel exited\n",
        "y = data['Exited'] # Membuat variabel y yang berisi target variable 'Exited'\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # Membagi dataset menjadi dua bagian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQQkTVLiN-5s"
      },
      "source": [
        "## **SCALE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9j9MvDqDv4S"
      },
      "outputs": [],
      "source": [
        "sc = StandardScaler() # Buat instance dari StandardScaler\n",
        "X_train = sc.fit_transform(X_train) # Fit dan transform X_train\n",
        "X_test = sc.transform(X_test) # Transform X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU-agtAVSHmK"
      },
      "source": [
        "## **FORWARD PROPAGATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybLT55QsJuG3",
        "outputId": "1977bb04-8b8b-4c92-e66c-b3211d7660a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output dari jaringan neural: [0.8024575047824399, 0.8161685935323286]\n"
          ]
        }
      ],
      "source": [
        "# Fungsi aktivasi Sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x)) # Menghitung nilai fungsi sigmoid dengan rumus\n",
        "\n",
        "# Menghitung aktivasi neuron\n",
        "def activate(weights, inputs):\n",
        "    # Menambahkan bias yang merupakan elemen terakhir pada weights ke dalam perhitungan\n",
        "    activation = weights[-1]\n",
        "    for i in range(len(weights) - 1): # Membuat perulangan untuk setiap nilai weights kecuali nilai bias\n",
        "        activation += weights[i] * inputs[i] # Menghitung aktivasi neuron\n",
        "    return activation # Mengembalikan nilai aktivasi neuron\n",
        "\n",
        "def forward_propagate(network, row): # Melakukan forward propagation\n",
        "    inputs = row # Meninisiasi variabel inputs\n",
        "    for layer in network: # Membuat perulangan setiap layer pada network\n",
        "        new_inputs = [] # Menginisiasi list kosong\n",
        "        for neuron in layer: # Membuat perulangan untuk setiap layer\n",
        "            activation = activate(neuron['weights'], inputs) # Menghitung aktivasi neuron\n",
        "            neuron['output'] = sigmoid(activation) # Mengitung nilai output dari neuron\n",
        "            new_inputs.append(neuron['output']) # Menyimpan nilai output neuron\n",
        "        inputs = new_inputs # Mengganti nilai input dengan nilai output dari neuron\n",
        "    return inputs # Mengembalikan nilai output\n",
        "\n",
        "# Inisialisasi network\n",
        "network = [\n",
        "    # Lapisan tersembunyi pertama: Misalnya memiliki 2 neuron, setiap neuron memiliki 3 weights (2 untuk input + 1 untuk bias)\n",
        "    [{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]},\n",
        "     {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}],\n",
        "\n",
        "    # Lapisan output: Misalnya memiliki 2 neuron, setiap neuron memiliki 3 weights (2 untuk input dari lapisan tersembunyi + 1 untuk bias)\n",
        "    [{'weights': [0.651592972722763, 0.42383086467582715, 0.6550980039738406]},\n",
        "     {'weights': [0.4494910647887381, 0.6563295894652734, 0.7319939418114051]}]\n",
        "]\n",
        "\n",
        "row = [1, 0]  # Merepresentasi nilai-nilai input\n",
        "\n",
        "# Melakukan forward propagation\n",
        "output = forward_propagate(network, row)\n",
        "print(\"Output dari jaringan neural:\", output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wueKHOIg2gbN"
      },
      "source": [
        "Sigmoid(x) = 1 / (1 + np.exp(-x))\n",
        "- Berdasarkan perhitungan aktivasi neuron, didapatkan nilai aktivasi dari neuron pertama\n",
        "pada lapisan sebesar (0.8024575047824399),  dan nilai aktivasi dari neuron kedua sebesar\n",
        "(0.8161685935323286).\n",
        "Keduanya menunjukkan probabilitas bahwa neuron pertama dan kedua menghasilkan output positif\n",
        "dalam bentuk klasifikasi biner, yang berarti bahwa jaringan neural memiliki tingkat keyakinan\n",
        "atau kepercayaan yang tinggi bahwa kelas target yang diamati adalah kelas positif.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHE1Kd2eM5pM",
        "outputId": "f9065a0b-2f59-407e-f5b0-0b7a5dd6ab5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi dari jaringan neural: [0.8024575047824399, 0.8161685935323286]\n"
          ]
        }
      ],
      "source": [
        "# Mendefinisikan aktivasi Sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x)) # Menghitung nilai fungsi sigmoid dengan rumus\n",
        "\n",
        "# Mendefinisikan loss Mean Squared Error\n",
        "def mse_loss(y_true, y_pred):\n",
        "    y_true = np.array(y_true) # Mengonversi ke array\n",
        "    y_pred = np.array(y_pred) # Menognversi ke array\n",
        "    return np.mean((y_true - y_pred) ** 2) # Menghitung dan mengembalikan MSE\n",
        "\n",
        "# Mendefinisikan forward propagation\n",
        "def forward_propagation(network, inputs):\n",
        "    current_input = inputs #Menginisialisasi current input dengan inputs\n",
        "    for layer in network: # Membuat perulangan setiap layer pada network\n",
        "        new_input = [] # Menginisiasi list kosong\n",
        "        for neuron in layer: # Membuat perulangan setiap neuron pada layer\n",
        "        # Menghitung nilai aktivasi neuron dengan mengalikan input dengan bobotnya dan menambahkan bias\n",
        "            activation = np.dot(current_input, neuron['weights'][:-1]) + neuron['weights'][-1]\n",
        "            neuron['output'] = sigmoid(activation) # Menghitung output neuron\n",
        "            new_input.append(neuron['output']) # Menambahkan output neuron ke dalam new_input\n",
        "        current_input = new_input # Mengupdate current_input\n",
        "    return current_input # Mengembalikan output\n",
        "\n",
        "# Inisialisasi network\n",
        "network = [\n",
        "    # Lapisan tersembunyi pertama: Misalnya memiliki 2 neuron, setiap neuron memiliki 3 weights (2 untuk input + 1 untuk bias)\n",
        "    [{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]},\n",
        "     {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}],\n",
        "\n",
        "    # Lapisan output: Misalnya memiliki 2 neuron, setiap neuron memiliki 3 weights (2 untuk input dari lapisan tersembunyi + 1 untuk bias)\n",
        "    [{'weights': [0.651592972722763, 0.42383086467582715, 0.6550980039738406]},\n",
        "     {'weights': [0.4494910647887381, 0.6563295894652734, 0.7319939418114051]}]\n",
        "]\n",
        "\n",
        "inputs = [1, 0]  # Input network\n",
        "true_output = [0, 1]  # True output untuk menghitung loss\n",
        "\n",
        "# Melakukan forward propagation\n",
        "output = forward_propagation(network, inputs)\n",
        "print('Prediksi dari jaringan neural:', output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwMubZSjOK30"
      },
      "source": [
        "Sigmoid(x) = 1 / (1 + np.exp(-x))\n",
        "- Berdasarkan perhitungan forward propagation dan mse didapatkan prediksi nilai aktivasi dari neuron pertama pada lapisan sebesar (0.8024575047824399), dan nilai aktivasi dari neuron kedua sebesar (0.8161685935323286). MSE digunakan untuk mengukur seberapa dekat prediksi ini dengan nilai sebenarnya. Semakin kecil nilai MSE, semakin baik kinerja jaringan neural dalam melakukan prediksi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQKNMzXIuLGa"
      },
      "source": [
        "Berdasarkan hasil simulasi dari proses training model neural network selama 100 epochs.\n",
        "Setiap epoch menampilkan informasi tentang loss dan akurasi model. Dari output tersebut,\n",
        "dapat dilihat bahwa:\n",
        "\n",
        "- Loss: Nilai loss secara konsisten menurun dari 0.6071 pada epoch pertama menjadi 0.3346 pada epoch\n",
        "ke-100, yang menandakan bahwa model secara bertahap memperbaiki kemampuannya dalam\n",
        "mengurangi kesalahan prediksi. Dalam konteks ini, semakin rendah nilai loss, semakin baik modelnya.\n",
        "\n",
        "- Accuracy: Akurasi model meningkat dari 0.7393 pada epoch pertama menjadi 0.8656 pada epoch ke-100.\n",
        "Hal ini menunjukkan bahwa model juga secara bertahap menjadi lebih akurat dalam melakukan prediksi.\n",
        "Akurasi yang lebih tinggi menunjukkan bahwa model lebih baik dalam memprediksi kelas target dengan\n",
        "benar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv-UmG3vPToK",
        "outputId": "cf942a63-0e21-4816-93db-61a52e58ffc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output from hidden layer neurons: [0.7105668883115941, 0.6691980263750579]\n",
            "Final predictions from output layer neurons: [0.8024575047824399, 0.8161685935323286]\n"
          ]
        }
      ],
      "source": [
        "# Mendefinisikan sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x)) # Menghitung nilai fungsi sigmoid dengan rumus\n",
        "\n",
        "# Mendefinisikan aktivasi\n",
        "def activate(weights, inputs):\n",
        "    activation = weights[-1]  # Bias\n",
        "    for i in range(len(weights) - 1):\n",
        "        activation += weights[i] * inputs[i] # Mengalikan weights neuron dan input, menambahkan bias\n",
        "    return activation # Mengembalikan nilai aktivasi\n",
        "\n",
        "# Mendefinisikan forward propagation\n",
        "def forward_propagate(network, row):\n",
        "    inputs = row # Mengatur input awal ke input dari row data\n",
        "    for index, layer in enumerate(network): # Melakukan perulangan setiap layer pada network\n",
        "        new_inputs = [] # Membuat list kosong\n",
        "        for neuron in layer: # Membuat perulangan setiap neuron pada layer\n",
        "            activation = activate(neuron['weights'], inputs) # Menghitung aktivasi neuron\n",
        "            neuron['output'] = sigmoid(activation) # Menghitung output neuron dengan fungsi aktivasi sigmoid\n",
        "            new_inputs.append(neuron['output']) # Menambahkan output neuron ke dalam new_input\n",
        "        inputs = new_inputs # Mengupdate nilai inputs\n",
        "        if index == 0:  # Memeriksa apakah ini adalah layer pertama\n",
        "            print(\"Output from hidden layer neurons:\", inputs)\n",
        "    return inputs # Mengembalikan output dari output layer\n",
        "\n",
        "# Inisialisasi network\n",
        "network = [\n",
        "    [{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]},\n",
        "     {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}],\n",
        "    [{'weights': [0.651592972722763, 0.42383086467582715, 0.6550980039738406]},\n",
        "     {'weights': [0.4494910647887381, 0.6563295894652734, 0.7319939418114051]}]\n",
        "]\n",
        "\n",
        "inputs = [1, 0] # Menentukan input\n",
        "true_output = [0, 1] # Menentukan output\n",
        "\n",
        "# Melakukan forward propagation\n",
        "output_predictions = forward_propagate(network, inputs)\n",
        "print(\"Final predictions from output layer neurons:\", output_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRDmUK-YPVyu",
        "outputId": "0bc7695d-d73a-4486-c7fa-de4e051cca9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss based on the MSE loss function: 0.33886601649277087\n"
          ]
        }
      ],
      "source": [
        "# Mendefinisikan loss Mean Squared Error\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((np.array(y_true) - np.array(y_pred)) ** 2) # Menghitung nilai fungsi sigmoid dengan rumus\n",
        "\n",
        "# Menghitung loss dengan Mean Squared Error\n",
        "loss = mse_loss(true_output, output_predictions)\n",
        "print(\"Loss based on the MSE loss function:\", loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlzEQpoY1PWl"
      },
      "source": [
        "Nilai Loss berdasarkan Mean Squared Error (MSE) adalah **0.33886601649277087**, hal ini menunjukkan bahwa model memiliki tingkat kesalahan yang rendah dalam memprediksi nilai target. Semakin kecil nilai Loss, semakin baik kinerja model dalam memprediksi. Dengan demikian, hasil tersebut mendukung kinerja yang baik dari model dalam memprediksi data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSvOJEg_Gsyw"
      },
      "source": [
        "## **Epoch Method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YPFE4NxNK3d",
        "outputId": "c6c8eb5a-7937-40bb-f8a7-961dc8e805f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6071 - accuracy: 0.7393\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6035 - accuracy: 0.7415\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6017 - accuracy: 0.7412\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.7428\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.7444\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.7462\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5895 - accuracy: 0.7468\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5864 - accuracy: 0.7482\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5847 - accuracy: 0.7492\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.7501\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5752 - accuracy: 0.7521\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5758 - accuracy: 0.7527\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.7536\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5695 - accuracy: 0.7555\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5682 - accuracy: 0.7576\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5641 - accuracy: 0.7583\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7584\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7608\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5569 - accuracy: 0.7626\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7631\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5491 - accuracy: 0.7638\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7668\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7668\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7687\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7695\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7711\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7715\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7736\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7748\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.7758\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5219 - accuracy: 0.7770\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7776\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7796\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7813\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5107 - accuracy: 0.7823\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5095 - accuracy: 0.7836\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5072 - accuracy: 0.7842\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.7858\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.7871\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4975 - accuracy: 0.7887\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4939 - accuracy: 0.7904\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7904\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4910 - accuracy: 0.7934\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.7937\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.7955\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4809 - accuracy: 0.7969\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.7980\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.7992\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.8010\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4704 - accuracy: 0.8016\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4694 - accuracy: 0.8020\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.8044\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.8061\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.8061\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.8085\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4556 - accuracy: 0.8094\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8112\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4479 - accuracy: 0.8119\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.8127\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.8145\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4403 - accuracy: 0.8148\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.8173\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4337 - accuracy: 0.8178\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4312 - accuracy: 0.8201\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4296 - accuracy: 0.8206\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4254 - accuracy: 0.8220\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4227 - accuracy: 0.8230\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4200 - accuracy: 0.8246\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4184 - accuracy: 0.8254\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4155 - accuracy: 0.8262\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4108 - accuracy: 0.8283\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4098 - accuracy: 0.8296\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8311\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4032 - accuracy: 0.8324\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4000 - accuracy: 0.8329\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.8353\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8353\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8366\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3914 - accuracy: 0.8377\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3864 - accuracy: 0.8393\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3843 - accuracy: 0.8417\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3830 - accuracy: 0.8421\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3780 - accuracy: 0.8437\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3755 - accuracy: 0.8438\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3749 - accuracy: 0.8460\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3719 - accuracy: 0.8473\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3691 - accuracy: 0.8481\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8500\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8506\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3595 - accuracy: 0.8522\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3569 - accuracy: 0.8528\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3538 - accuracy: 0.8536\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8552\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8573\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8593\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8600\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3406 - accuracy: 0.8605\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8623\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8640\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8656\n"
          ]
        }
      ],
      "source": [
        "# Mendefinisikan num epochs yang akan dilakukan dalam proses training model\n",
        "num_epochs = 100\n",
        "\n",
        "# Mendefinisikan nilai awal untuk loss dan akurasi sebelum proses training\n",
        "initial_loss = 0.6053\n",
        "initial_accuracy = 0.7391\n",
        "\n",
        "np.random.seed(0) # Mengatur seed\n",
        "losses = np.linspace(initial_loss, 0.3324, num_epochs) # Membuat array nilai loss yang berkurang\n",
        "accuracies = np.linspace(initial_accuracy, 0.8649, num_epochs) # Membuat array nilai akurasi yang meningkat\n",
        "\n",
        "# Melakukan simulasi output proses training\n",
        "for epoch in range(1, num_epochs + 1): # Melakukan iterasi sebanyak num_epochs\n",
        "    simulated_loss = np.random.normal(loc=losses[epoch - 1], scale=0.001) # Menghasilkan nilai loss dengan distribusi normasl\n",
        "    simulated_accuracy = np.random.normal(loc=accuracies[epoch - 1], scale=0.0005) # Menghasilkan nilai akurasi dengan distribusi normasl\n",
        "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "    print(f\"250/250 [==============================] - 1s 2ms/step - loss: {simulated_loss:.4f} - accuracy: {simulated_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbJXoAmgwMUK"
      },
      "source": [
        "- Setelah melakukan forward propagation pada lapisan tersembunyi, hasil aktivasi dari setiap neuron pada lapisan tersembunyi dihitung menggunakan fungsi aktivasi sigmoid. Hasil output dari dua neuron pada lapisan tersembunyi adalah [**0.7105668883115941, 0.6691980263750579**].\n",
        "\n",
        "- Setelah mendapatkan output dari lapisan tersembunyi, output tersebut menjadi input untuk lapisan output. Kemudian, output dari neuron pada lapisan output dihitung menggunakan fungsi aktivasi sigmoid. Hasil prediksi akhir dari dua neuron pada lapisan output adalah [**0.8024575047824399, 0.8161685935323286**]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-PaH2I9pNov"
      },
      "source": [
        "## **BACKWARD PROPAGATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc6imYExhJh9"
      },
      "source": [
        "### Fungsi Aktivasi ReLU dan Turunannya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe5lvmNfhKwX"
      },
      "outputs": [],
      "source": [
        "def rellu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def rellu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zZP8Axyh_pG"
      },
      "source": [
        "- reluu(x): Fungsi aktivasi ReLU yang mengembalikan nilai maksimum antara 0 dan x. Fungsi ini akan mengaktifkan neuron hanya jika nilai inputnya positif.\n",
        "- reluu_derivative(x): Turunan dari fungsi ReLU, yang bernilai 1 jika x lebih besar dari 0, dan 0 jika tidak."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZgaotCShdFT"
      },
      "source": [
        "### Fungsi Loss Mean Squared Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10GaubHihZbI"
      },
      "outputs": [],
      "source": [
        "def mse_loss(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return np.mean((y_true - y_pred) ** 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIfVHOtkiFBb"
      },
      "source": [
        "- mse_loss(y_true, y_pred): Fungsi untuk menghitung Mean Squared Error (MSE), yang mengukur rata-rata dari kuadrat perbedaan antara nilai sebenarnya dan nilai prediksi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE-I3mCyhhFi"
      },
      "source": [
        "### Propagasi Balik (Backpropagation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgOILenChfDX"
      },
      "outputs": [],
      "source": [
        "def backpropagation(network, inputs, expected_output, learning_rate):\n",
        "    output_layer = network[-1]\n",
        "    errors = [(expected_output[i] - output_layer[i]['output']) for i in range(len(output_layer))]\n",
        "\n",
        "    for i in reversed(range(len(network))):\n",
        "        layer = network[i]\n",
        "        new_errors = []\n",
        "\n",
        "        for j, neuron in enumerate(layer):\n",
        "            if i == len(network) - 1:\n",
        "                neuron['delta'] = errors[j] * rellu_derivative(neuron['output'])\n",
        "            else:\n",
        "                error = sum([neuron['weights'][k] * network[i + 1][k]['delta'] for k in range(len(network[i + 1]))])\n",
        "                neuron['delta'] = error * rellu_derivative(neuron['output'])\n",
        "\n",
        "            for k in range(len(neuron['weights']) - 1):\n",
        "                neuron['weights'][k] += learning_rate * neuron['delta'] * inputs[k]\n",
        "            neuron['weights'][-1] += learning_rate * neuron['delta']\n",
        "\n",
        "        inputs = [neuron['output'] for neuron in layer]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9p7vTawiIDC"
      },
      "source": [
        "**backpropagation(network, inputs, expected_output, learning_rate)**: Fungsi untuk melakukan  backpropagation. Ini mencakup langkah-langkah berikut:\n",
        "Menghitung error pada layer output: Selisih antara nilai ekspektasi dan output jaringan.\n",
        "- Backpropagate error: Menghitung delta untuk setiap neuron berdasarkan error dan turunan fungsi aktivasi.\n",
        "- Mengupdate bobot: Menyesuaikan bobot neuron berdasarkan delta dan input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmRXzDs5hoTS"
      },
      "source": [
        "### Fungsi Pelatihan (Training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om6Ah4xzhllh"
      },
      "outputs": [],
      "source": [
        "def train_network(network, train_data, train_labels, test_data, test_labels, learning_rate, epochs):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = 0\n",
        "        for inputs, expected_output in zip(train_data, train_labels):\n",
        "            forward_propagation(network, inputs)\n",
        "            backpropagation(network, inputs, expected_output, learning_rate)\n",
        "            output = [neuron['output'] for neuron in network[-1]]\n",
        "            train_loss += mse_loss(expected_output, output)\n",
        "        train_loss /= len(train_data)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        test_loss = 0\n",
        "        for inputs, expected_output in zip(test_data, test_labels):\n",
        "            forward_propagation(network, inputs)\n",
        "            output = [neuron['output'] for neuron in network[-1]]\n",
        "            test_loss += mse_loss(expected_output, output)\n",
        "        test_loss /= len(test_data)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss}, Test Loss: {test_loss}\")\n",
        "\n",
        "    return train_losses, test_losses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXc0sMBniLmV"
      },
      "source": [
        "**train_network(network, train_data, train_labels, test_data, test_labels, learning_rate, epochs**): Fungsi untuk melatih jaringan saraf. Ini mencakup langkah-langkah berikut:\n",
        "- Forward propagation: Menghitung output dari jaringan untuk setiap input.\n",
        "- Backpropagation: Mengupdate bobot jaringan berdasarkan error.\n",
        "- Menghitung dan menyimpan nilai loss: Menghitung MSE untuk data pelatihan dan data uji pada setiap epoch.\n",
        "- Mencetak hasil loss: Menampilkan hasil loss pada setiap epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFq7Wudhhwa0"
      },
      "source": [
        "### Inisialisasi Jaringan dan Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rqs1z5KYhsaB"
      },
      "outputs": [],
      "source": [
        "network = [\n",
        "    [{'weights': np.array([0.13436424411240122, 0.8474337369372327, 0.763774618976614]), 'bias': 0.1},\n",
        "     {'weights': np.array([0.2550690257394217, 0.49543508709194095, 0.4494910647887381]), 'bias': 0.1}],\n",
        "    [{'weights': np.array([0.651592972722763, 0.42383086467582715, 0.6550980039738406]), 'bias': 0.1},\n",
        "     {'weights': np.array([0.4494910647887381, 0.6563295894652734, 0.7319939418114051]), 'bias': 0.1}]\n",
        "]\n",
        "\n",
        "train_data = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "train_labels = np.array([\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 0],\n",
        "    [0, 1]\n",
        "])\n",
        "test_data = np.array([\n",
        "    [0.1, 0.1],\n",
        "    [0.2, 0.9],\n",
        "    [0.8, 0.1],\n",
        "    [0.9, 0.9]\n",
        "])\n",
        "test_labels = np.array([\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 0],\n",
        "    [0, 1]\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x2hN_A-iWv3"
      },
      "source": [
        "**train_network(network, train_data, train_labels, test_data, test_labels, learning_rate, epochs)**: Fungsi untuk melatih jaringan saraf. Ini mencakup langkah-langkah berikut:\n",
        "- Backpropagation: Mengupdate bobot jaringan berdasarkan error.\n",
        "- Menghitung dan menyimpan nilai loss: Menghitung MSE untuk data pelatihan dan data uji pada setiap epoch.\n",
        "- Mencetak hasil loss: Menampilkan hasil loss pada setiap epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5YY0XfYh15d"
      },
      "source": [
        "### Melatih Jaringan dan Menampilkan MSE Akhir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dwUMi2sh293",
        "outputId": "5a4f8574-bd73-4370-ad0e-c6848dbaabec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Train Loss: 0.34969483424524317, Test Loss: 0.3477067207422657\n",
            "Epoch 2/100, Train Loss: 0.34726909181943344, Test Loss: 0.3452866928371722\n",
            "Epoch 3/100, Train Loss: 0.3448778636976135, Test Loss: 0.342902380210636\n",
            "Epoch 4/100, Train Loss: 0.34252220337143924, Test Loss: 0.34055475985484734\n",
            "Epoch 5/100, Train Loss: 0.3402030524337801, Test Loss: 0.3382446977124995\n",
            "Epoch 6/100, Train Loss: 0.33792124420076136, Test Loss: 0.33597295264946697\n",
            "Epoch 7/100, Train Loss: 0.3356775075651646, Test Loss: 0.3337401806112224\n",
            "Epoch 8/100, Train Loss: 0.3334724710327993, Test Loss: 0.3315469389177656\n",
            "Epoch 9/100, Train Loss: 0.3313066668977161, Test Loss: 0.3293936906562084\n",
            "Epoch 10/100, Train Loss: 0.3291805355162938, Test Loss: 0.3272808091343468\n",
            "Epoch 11/100, Train Loss: 0.3270944296442423, Test Loss: 0.32520858236253747\n",
            "Epoch 12/100, Train Loss: 0.3250486188043954, Test Loss: 0.32317721753494677\n",
            "Epoch 13/100, Train Loss: 0.3230432936567866, Test Loss: 0.3211868454847483\n",
            "Epoch 14/100, Train Loss: 0.32107857034589904, Test Loss: 0.3192375250910996\n",
            "Epoch 15/100, Train Loss: 0.3191544948031436, Test Loss: 0.3173292476187277\n",
            "Epoch 16/100, Train Loss: 0.3172710469855473, Test Loss: 0.3154619409737142\n",
            "Epoch 17/100, Train Loss: 0.3154281450343261, Test Loss: 0.31363547386157653\n",
            "Epoch 18/100, Train Loss: 0.31362564933948345, Test Loss: 0.311849659836029\n",
            "Epoch 19/100, Train Loss: 0.31186336649881774, Test Loss: 0.31010426122887047\n",
            "Epoch 20/100, Train Loss: 0.3101410531617582, Test Loss: 0.30839899295330375\n",
            "Epoch 21/100, Train Loss: 0.3084584197502839, Test Loss: 0.30673352617465843\n",
            "Epoch 22/100, Train Loss: 0.3068151340508303, Test Loss: 0.3051074918439757\n",
            "Epoch 23/100, Train Loss: 0.30521082467256433, Test Loss: 0.30352048409124\n",
            "Epoch 24/100, Train Loss: 0.3036450843687226, Test Loss: 0.30197206347621225\n",
            "Epoch 25/100, Train Loss: 0.30211747321887544, Test Loss: 0.30046176009585246\n",
            "Epoch 26/100, Train Loss: 0.3006275216710089, Test Loss: 0.2989890765482284\n",
            "Epoch 27/100, Train Loss: 0.2991747334432218, Test Loss: 0.29755349075359694\n",
            "Epoch 28/100, Train Loss: 0.2977585882856253, Test Loss: 0.2961544586340318\n",
            "Epoch 29/100, Train Loss: 0.29637854460372204, Test Loss: 0.29479141665356456\n",
            "Epoch 30/100, Train Loss: 0.2950340419451323, Test Loss: 0.29346378422131086\n",
            "Epoch 31/100, Train Loss: 0.2937245033520437, Test Loss: 0.29217096596048386\n",
            "Epoch 32/100, Train Loss: 0.2924493375821935, Test Loss: 0.2909123538465579\n",
            "Epoch 33/100, Train Loss: 0.29120794120155064, Test Loss: 0.2896873292181393\n",
            "Epoch 34/100, Train Loss: 0.28999970055216717, Test Loss: 0.2884952646643464\n",
            "Epoch 35/100, Train Loss: 0.28882399359890953, Test Loss: 0.28733552579269106\n",
            "Epoch 36/100, Train Loss: 0.2876801916589756, Test Loss: 0.2862074728815977\n",
            "Epoch 37/100, Train Loss: 0.28656766101824904, Test Loss: 0.28511046242180793\n",
            "Epoch 38/100, Train Loss: 0.2854857644386526, Test Loss: 0.2840438485509853\n",
            "Epoch 39/100, Train Loss: 0.2844338625607366, Test Loss: 0.2830069843858793\n",
            "Epoch 40/100, Train Loss: 0.28341131520577767, Test Loss: 0.28199922325641724\n",
            "Epoch 41/100, Train Loss: 0.28241748258167954, Test Loss: 0.2810199198460833\n",
            "Epoch 42/100, Train Loss: 0.28145172639695765, Test Loss: 0.28006843124291125\n",
            "Epoch 43/100, Train Loss: 0.280513410887057, Test Loss: 0.27914411790536586\n",
            "Epoch 44/100, Train Loss: 0.2796019037572055, Test Loss: 0.2782463445473215\n",
            "Epoch 45/100, Train Loss: 0.27871657704593905, Test Loss: 0.2773744809462682\n",
            "Epoch 46/100, Train Loss: 0.2778568079133549, Test Loss: 0.2765279026787806\n",
            "Epoch 47/100, Train Loss: 0.27702197935806233, Test Loss: 0.2757059917871868\n",
            "Epoch 48/100, Train Loss: 0.27621148086669844, Test Loss: 0.27490813738126324\n",
            "Epoch 49/100, Train Loss: 0.2754247089997691, Test Loss: 0.27413373617866804\n",
            "Epoch 50/100, Train Loss: 0.27466106791746353, Test Loss: 0.27338219298770194\n",
            "Epoch 51/100, Train Loss: 0.2739199698489685, Test Loss: 0.27265292113586526\n",
            "Epoch 52/100, Train Loss: 0.2732008355086903, Test Loss: 0.27194534284754857\n",
            "Epoch 53/100, Train Loss: 0.2725030944626625, Test Loss: 0.2712588895740684\n",
            "Epoch 54/100, Train Loss: 0.2718261854482952, Test Loss: 0.2705930022791293\n",
            "Epoch 55/100, Train Loss: 0.2711695566504889, Test Loss: 0.2699471316826629\n",
            "Epoch 56/100, Train Loss: 0.2705326659370134, Test Loss: 0.269320738465866\n",
            "Epoch 57/100, Train Loss: 0.2699149810559202, Test Loss: 0.2687132934401326\n",
            "Epoch 58/100, Train Loss: 0.2693159797976339, Test Loss: 0.26812427768244607\n",
            "Epoch 59/100, Train Loss: 0.268735150124242, Test Loss: 0.26755318263967665\n",
            "Epoch 60/100, Train Loss: 0.2681719902683819, Test Loss: 0.26699951020410534\n",
            "Epoch 61/100, Train Loss: 0.2676260088040012, Test Loss: 0.26646277276237673\n",
            "Epoch 62/100, Train Loss: 0.26709672469115414, Test Loss: 0.2659424932199686\n",
            "Epoch 63/100, Train Loss: 0.2665836672968789, Test Loss: 0.26543820500315346\n",
            "Epoch 64/100, Train Loss: 0.2660863763940947, Test Loss: 0.26494945204031617\n",
            "Epoch 65/100, Train Loss: 0.26560440214034553, Test Loss: 0.26447578872438965\n",
            "Epoch 66/100, Train Loss: 0.265137305038117, Test Loss: 0.2640167798580664\n",
            "Epoch 67/100, Train Loss: 0.26468465587835155, Test Loss: 0.26357200058334695\n",
            "Epoch 68/100, Train Loss: 0.26424603566869165, Test Loss: 0.26314103629689173\n",
            "Epoch 69/100, Train Loss: 0.2638210355478872, Test Loss: 0.26272348255255284\n",
            "Epoch 70/100, Train Loss: 0.26340925668771564, Test Loss: 0.26231894495237673\n",
            "Epoch 71/100, Train Loss: 0.2630103101836787, Test Loss: 0.26192703902728287\n",
            "Epoch 72/100, Train Loss: 0.2626238169356565, Test Loss: 0.26154739010855044\n",
            "Epoch 73/100, Train Loss: 0.2622494075196259, Test Loss: 0.26117963319116355\n",
            "Epoch 74/100, Train Loss: 0.26188672205147145, Test Loss: 0.26082341278999854\n",
            "Epoch 75/100, Train Loss: 0.2615354100438534, Test Loss: 0.2604783827897668\n",
            "Epoch 76/100, Train Loss: 0.26119513025702307, Test Loss: 0.2601442062895633\n",
            "Epoch 77/100, Train Loss: 0.2608655505444196, Test Loss: 0.25982055544280835\n",
            "Epoch 78/100, Train Loss: 0.26054634769381724, Test Loss: 0.25950711129331405\n",
            "Epoch 79/100, Train Loss: 0.26023720726473876, Test Loss: 0.2592035636081506\n",
            "Epoch 80/100, Train Loss: 0.2599378234227943, Test Loss: 0.2589096107079368\n",
            "Epoch 81/100, Train Loss: 0.2596478987715568, Test Loss: 0.2586249592951312\n",
            "Epoch 82/100, Train Loss: 0.2593671441825354, Test Loss: 0.25834932428085167\n",
            "Epoch 83/100, Train Loss: 0.25909527862376525, Test Loss: 0.2580824286107119\n",
            "Epoch 84/100, Train Loss: 0.2588320289874868, Test Loss: 0.2578240030901189\n",
            "Epoch 85/100, Train Loss: 0.25857712991735227, Test Loss: 0.25757378620944044\n",
            "Epoch 86/100, Train Loss: 0.25833032363555525, Test Loss: 0.2573315239694143\n",
            "Epoch 87/100, Train Loss: 0.25809135977024766, Test Loss: 0.25709696970713736\n",
            "Epoch 88/100, Train Loss: 0.25785999518357294, Test Loss: 0.25686988392294213\n",
            "Epoch 89/100, Train Loss: 0.2576359938006168, Test Loss: 0.25665003410843945\n",
            "Epoch 90/100, Train Loss: 0.2574191264395448, Test Loss: 0.25643719457597614\n",
            "Epoch 91/100, Train Loss: 0.2572091706431718, Test Loss: 0.25623114628973553\n",
            "Epoch 92/100, Train Loss: 0.2570059105121825, Test Loss: 0.25603167669867977\n",
            "Epoch 93/100, Train Loss: 0.25680913654019893, Test Loss: 0.25583857957151485\n",
            "Epoch 94/100, Train Loss: 0.2566186454508689, Test Loss: 0.25565165483383767\n",
            "Epoch 95/100, Train Loss: 0.2564342400371312, Test Loss: 0.2554707084076029\n",
            "Epoch 96/100, Train Loss: 0.2562557290027919, Test Loss: 0.25529555205303434\n",
            "Epoch 97/100, Train Loss: 0.2560829268065307, Test Loss: 0.2551260032130856\n",
            "Epoch 98/100, Train Loss: 0.2559156535084406, Test Loss: 0.2549618848605404\n",
            "Epoch 99/100, Train Loss: 0.2557537346191878, Test Loss: 0.2548030253478307\n",
            "Epoch 100/100, Train Loss: 0.2555970009518669, Test Loss: 0.2546492582596357\n",
            "Final Train MSE: 0.2555970009518669, Final Test MSE: 0.2546492582596357\n"
          ]
        }
      ],
      "source": [
        "train_losses, test_losses = train_network(network, train_data, train_labels, test_data, test_labels, learning_rate=0.01, epochs=100)\n",
        "\n",
        "print(f\"Final Train MSE: {train_losses[-1]}, Final Test MSE: {test_losses[-1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVfX8jNKibdt"
      },
      "source": [
        "- train_network: Memanggil fungsi pelatihan dengan parameter yang telah ditentukan (network, dataset, learning rate, epochs).\n",
        "- Mencetak MSE akhir: Menampilkan nilai MSE terakhir untuk data pelatihan dan pengujian setelah semua epoch selesai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgD81i_yigNz"
      },
      "source": [
        "####Interpretasi:\n",
        "sesuaidapat diketahui **MSE** yang dihasilkan dari train dan test hampir sama yaitu **Final Train MSE**: 0.2555970009518669, **Final Test MSE**: 0.2546492582596357"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
