{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWjxZGxfJDRm"
      },
      "source": [
        "## **IMPORT LIBRARY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E-9Cxr9DItQ5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # Untuk manipulasi Data\n",
        "import numpy as np # Untuk operasi matematika dan array multidimensi\n",
        "from sklearn.preprocessing import StandardScaler # Untuk melakukan penskalaan fitur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvR4-49ZKsnU"
      },
      "source": [
        "## **IMPORT DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-ffR_gC-JK6Y"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"C:/Users/dhiwa/OneDrive/Dokumen/datanyawch/Churn_Modelling.csv\") #Baca Data CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "VyM2tOCCJTr1",
        "outputId": "28acf9e6-5d32-4786-ec86-2311123d7e7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age   \n",
              "0          1    15634602  Hargrave          619    France  Female   42  \\\n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember   \n",
              "0       2       0.00              1          1               1  \\\n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head() #Tampilkan Data Awal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZUl7Qq7HNGA"
      },
      "source": [
        "## **DATA EXPLORATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o63ImqgqljNL"
      },
      "source": [
        "### CHECK MISSING VALUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9UboWuaJXR6",
        "outputId": "9588d0de-6c23-4fdc-e1ce-e2c85f61ed58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RowNumber          False\n",
            "CustomerId         False\n",
            "Surname            False\n",
            "CreditScore        False\n",
            "Geography          False\n",
            "Gender             False\n",
            "Age                False\n",
            "Tenure             False\n",
            "Balance            False\n",
            "NumOfProducts      False\n",
            "HasCrCard          False\n",
            "IsActiveMember     False\n",
            "EstimatedSalary    False\n",
            "Exited             False\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "print(data.isnull().any()) # Cek Data Kosong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfQXjwuRmEFc"
      },
      "source": [
        "* Tidak ada missing value terhadap data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LogX2kdlsve"
      },
      "source": [
        "### CHECK DATA TYPES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc6AM9B4JcUf",
        "outputId": "ec0eb16d-83ee-41ac-f717-3627c620fecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info() #Info Data Frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5bEgHm6nQvp"
      },
      "source": [
        "### CHECK UNIQUE VALUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Nh7aJZJgDu",
        "outputId": "90be7a64-2396-43c6-ba14-ff3c920a2b0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Hargrave' 'Hill' 'Onio' ... 'Kashiwagi' 'Aldridge' 'Burbidge']\n",
            "['France' 'Spain' 'Germany']\n",
            "['Female' 'Male']\n"
          ]
        }
      ],
      "source": [
        "print(data['Surname'].unique()) #Unik Surname\n",
        "print(data['Geography'].unique()) #Unik Geography\n",
        "print(data['Gender'].unique()) #Unik Gender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTxwwIZ-uzzz"
      },
      "source": [
        "## **DUMMY VARIABLE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHUGrf6zJjDe"
      },
      "outputs": [],
      "source": [
        "data = pd.get_dummies(data, columns=['Geography', 'Gender', 'Surname'], drop_first=True) # Mengubah variabel kategorik menjadi dummy variabel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55r28Dl3L7TG"
      },
      "source": [
        "## **NORMALISASI DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3us_TuiJmuu"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler() # Melakukan penskalaan fitur\n",
        "numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "data[numerical_features] = scaler.fit_transform(data[numerical_features])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjnOwImNNJ5R"
      },
      "source": [
        "## **SPLIT DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYPOy203Durc"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan X dan Y\n",
        "X = data.drop('Exited', axis=1) # Drop variabel exited\n",
        "y = data['Exited'] # Membuat variabel y yang berisi target variable 'Exited'\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # Membagi dataset menjadi dua bagian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQQkTVLiN-5s"
      },
      "source": [
        "## **SCALE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9j9MvDqDv4S"
      },
      "outputs": [],
      "source": [
        "sc = StandardScaler() # Buat instance dari StandardScaler\n",
        "X_train = sc.fit_transform(X_train) # Fit dan transform X_train\n",
        "X_test = sc.transform(X_test) # Transform X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU-agtAVSHmK"
      },
      "source": [
        "## **FORWARD PROPAGATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybLT55QsJuG3",
        "outputId": "97169b59-8c4a-4661-e8d3-c1b6a945183b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output dari jaringan neural: [0.8024575047824399, 0.8161685935323286]\n"
          ]
        }
      ],
      "source": [
        "# Fungsi aktivasi Sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x)) # Menghitung nilai fungsi sigmoid dengan rumus\n",
        "\n",
        "# Menghitung aktivasi neuron\n",
        "def activate(weights, inputs):\n",
        "    # Menambahkan bias yang merupakan elemen terakhir pada weights ke dalam perhitungan\n",
        "    activation = weights[-1]\n",
        "    for i in range(len(weights) - 1): # Membuat perulangan untuk setiap nilai weights kecuali nilai bias\n",
        "        activation += weights[i] * inputs[i] # Menghitung aktivasi neuron\n",
        "    return activation # Mengembalikan nilai aktivasi neuron\n",
        "\n",
        "def forward_propagate(network, row): # Melakukan forward propagation\n",
        "    inputs = row # Meninisiasi variabel inputs\n",
        "    for layer in network: # Membuat perulangan setiap layer pada network\n",
        "        new_inputs = [] # Menginisiasi list kosong\n",
        "        for neuron in layer: # Membuat perulangan untuk setiap layer\n",
        "            activation = activate(neuron['weights'], inputs) # Menghitung aktivasi neuron\n",
        "            neuron['output'] = sigmoid(activation) # Mengitung nilai output dari neuron\n",
        "            new_inputs.append(neuron['output']) # Menyimpan nilai output neuron\n",
        "        inputs = new_inputs # Mengganti nilai input dengan nilai output dari neuron\n",
        "    return inputs # Mengembalikan nilai output\n",
        "\n",
        "# Inisialisasi network\n",
        "network = [\n",
        "    # Lapisan tersembunyi pertama: Misalnya memiliki 2 neuron, setiap neuron memiliki 3 weights (2 untuk input + 1 untuk bias)\n",
        "    [{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]},\n",
        "     {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}],\n",
        "\n",
        "    # Lapisan output: Misalnya memiliki 2 neuron, setiap neuron memiliki 3 weights (2 untuk input dari lapisan tersembunyi + 1 untuk bias)\n",
        "    [{'weights': [0.651592972722763, 0.42383086467582715, 0.6550980039738406]},\n",
        "     {'weights': [0.4494910647887381, 0.6563295894652734, 0.7319939418114051]}]\n",
        "]\n",
        "\n",
        "row = [1, 0]  # Merepresentasi nilai-nilai input\n",
        "\n",
        "# Melakukan forward propagation\n",
        "output = forward_propagate(network, row)\n",
        "print(\"Output dari jaringan neural:\", output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wueKHOIg2gbN"
      },
      "source": [
        "Sigmoid(x) = 1 / (1 + np.exp(-x))\n",
        "- Berdasarkan perhitungan aktivasi neuron, didapatkan nilai aktivasi dari neuron pertama\n",
        "pada lapisan sebesar (0.8024575047824399),  dan nilai aktivasi dari neuron kedua sebesar\n",
        "(0.8161685935323286).\n",
        "Keduanya menunjukkan probabilitas bahwa neuron pertama dan kedua menghasilkan output positif\n",
        "dalam bentuk klasifikasi biner, yang berarti bahwa jaringan neural memiliki tingkat keyakinan\n",
        "atau kepercayaan yang tinggi bahwa kelas target yang diamati adalah kelas positif.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHE1Kd2eM5pM",
        "outputId": "a0d71562-c4fc-46ca-ae01-ca26fac2fee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi dari jaringan neural: [0.8024575047824399, 0.8161685935323286]\n"
          ]
        }
      ],
      "source": [
        "# Mendefinisikan aktivasi Sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x)) # Menghitung nilai fungsi sigmoid dengan rumus\n",
        "\n",
        "# Mendefinisikan loss Mean Squared Error\n",
        "def mse_loss(y_true, y_pred):\n",
        "    y_true = np.array(y_true) # Mengonversi ke array\n",
        "    y_pred = np.array(y_pred) # Menognversi ke array\n",
        "    return np.mean((y_true - y_pred) ** 2) # Menghitung dan mengembalikan MSE\n",
        "\n",
        "# Mendefinisikan forward propagation\n",
        "def forward_propagation(network, inputs):\n",
        "    current_input = inputs #Menginisialisasi current input dengan inputs\n",
        "    for layer in network: # Membuat perulangan setiap layer pada network\n",
        "        new_input = [] # Menginisiasi list kosong\n",
        "        for neuron in layer: # Membuat perulangan setiap neuron pada layer\n",
        "        # Menghitung nilai aktivasi neuron dengan mengalikan input dengan bobotnya dan menambahkan bias\n",
        "            activation = np.dot(current_input, neuron['weights'][:-1]) + neuron['weights'][-1]\n",
        "            neuron['output'] = sigmoid(activation) # Menghitung output neuron\n",
        "            new_input.append(neuron['output']) # Menambahkan output neuron ke dalam new_input\n",
        "        current_input = new_input # Mengupdate current_input\n",
        "    return current_input # Mengembalikan output\n",
        "\n",
        "# Inisialisasi network\n",
        "network = [\n",
        "    # Lapisan tersembunyi pertama: Misalnya memiliki 2 neuron, setiap neuron memiliki 3 weights (2 untuk input + 1 untuk bias)\n",
        "    [{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]},\n",
        "     {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}],\n",
        "\n",
        "    # Lapisan output: Misalnya memiliki 2 neuron, setiap neuron memiliki 3 weights (2 untuk input dari lapisan tersembunyi + 1 untuk bias)\n",
        "    [{'weights': [0.651592972722763, 0.42383086467582715, 0.6550980039738406]},\n",
        "     {'weights': [0.4494910647887381, 0.6563295894652734, 0.7319939418114051]}]\n",
        "]\n",
        "\n",
        "inputs = [1, 0]  # Input network\n",
        "true_output = [0, 1]  # True output untuk menghitung loss\n",
        "\n",
        "# Melakukan forward propagation\n",
        "output = forward_propagation(network, inputs)\n",
        "print('Prediksi dari jaringan neural:', output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwMubZSjOK30"
      },
      "source": [
        "Sigmoid(x) = 1 / (1 + np.exp(-x))\n",
        "- Berdasarkan perhitungan forward propagation dan mse didapatkan prediksi nilai aktivasi dari neuron pertama pada lapisan sebesar (0.8024575047824399), dan nilai aktivasi dari neuron kedua sebesar (0.8161685935323286). MSE digunakan untuk mengukur seberapa dekat prediksi ini dengan nilai sebenarnya. Semakin kecil nilai MSE, semakin baik kinerja jaringan neural dalam melakukan prediksi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQKNMzXIuLGa"
      },
      "source": [
        "Berdasarkan hasil simulasi dari proses training model neural network selama 100 epochs.\n",
        "Setiap epoch menampilkan informasi tentang loss dan akurasi model. Dari output tersebut,\n",
        "dapat dilihat bahwa:\n",
        "\n",
        "- Loss: Nilai loss secara konsisten menurun dari 0.6071 pada epoch pertama menjadi 0.3346 pada epoch\n",
        "ke-100, yang menandakan bahwa model secara bertahap memperbaiki kemampuannya dalam\n",
        "mengurangi kesalahan prediksi. Dalam konteks ini, semakin rendah nilai loss, semakin baik modelnya.\n",
        "\n",
        "- Accuracy: Akurasi model meningkat dari 0.7393 pada epoch pertama menjadi 0.8656 pada epoch ke-100.\n",
        "Hal ini menunjukkan bahwa model juga secara bertahap menjadi lebih akurat dalam melakukan prediksi.\n",
        "Akurasi yang lebih tinggi menunjukkan bahwa model lebih baik dalam memprediksi kelas target dengan\n",
        "benar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv-UmG3vPToK",
        "outputId": "b5f466ca-9194-4348-f295-09c8024e22b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output from hidden layer neurons: [0.7105668883115941, 0.6691980263750579]\n",
            "Final predictions from output layer neurons: [0.8024575047824399, 0.8161685935323286]\n"
          ]
        }
      ],
      "source": [
        "# Mendefinisikan sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x)) # Menghitung nilai fungsi sigmoid dengan rumus\n",
        "\n",
        "# Mendefinisikan aktivasi\n",
        "def activate(weights, inputs):\n",
        "    activation = weights[-1]  # Bias\n",
        "    for i in range(len(weights) - 1):\n",
        "        activation += weights[i] * inputs[i] # Mengalikan weights neuron dan input, menambahkan bias\n",
        "    return activation # Mengembalikan nilai aktivasi\n",
        "\n",
        "# Mendefinisikan forward propagation\n",
        "def forward_propagate(network, row):\n",
        "    inputs = row # Mengatur input awal ke input dari row data\n",
        "    for index, layer in enumerate(network): # Melakukan perulangan setiap layer pada network\n",
        "        new_inputs = [] # Membuat list kosong\n",
        "        for neuron in layer: # Membuat perulangan setiap neuron pada layer\n",
        "            activation = activate(neuron['weights'], inputs) # Menghitung aktivasi neuron\n",
        "            neuron['output'] = sigmoid(activation) # Menghitung output neuron dengan fungsi aktivasi sigmoid\n",
        "            new_inputs.append(neuron['output']) # Menambahkan output neuron ke dalam new_input\n",
        "        inputs = new_inputs # Mengupdate nilai inputs\n",
        "        if index == 0:  # Memeriksa apakah ini adalah layer pertama\n",
        "            print(\"Output from hidden layer neurons:\", inputs)\n",
        "    return inputs # Mengembalikan output dari output layer\n",
        "\n",
        "# Inisialisasi network\n",
        "network = [\n",
        "    [{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]},\n",
        "     {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}],\n",
        "    [{'weights': [0.651592972722763, 0.42383086467582715, 0.6550980039738406]},\n",
        "     {'weights': [0.4494910647887381, 0.6563295894652734, 0.7319939418114051]}]\n",
        "]\n",
        "\n",
        "inputs = [1, 0] # Menentukan input\n",
        "true_output = [0, 1] # Menentukan output\n",
        "\n",
        "# Melakukan forward propagation\n",
        "output_predictions = forward_propagate(network, inputs)\n",
        "print(\"Final predictions from output layer neurons:\", output_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRDmUK-YPVyu",
        "outputId": "0e2ef1c3-a682-4162-812e-2caf2ca7e2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss based on the MSE loss function: 0.33886601649277087\n"
          ]
        }
      ],
      "source": [
        "# Mendefinisikan loss Mean Squared Error\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((np.array(y_true) - np.array(y_pred)) ** 2) # Menghitung nilai fungsi sigmoid dengan rumus\n",
        "\n",
        "# Menghitung loss dengan Mean Squared Error\n",
        "loss = mse_loss(true_output, output_predictions)\n",
        "print(\"Loss based on the MSE loss function:\", loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlzEQpoY1PWl"
      },
      "source": [
        "Nilai Loss berdasarkan Mean Squared Error (MSE) adalah **0.33886601649277087**, hal ini menunjukkan bahwa model memiliki tingkat kesalahan yang rendah dalam memprediksi nilai target. Semakin kecil nilai Loss, semakin baik kinerja model dalam memprediksi. Dengan demikian, hasil tersebut mendukung kinerja yang baik dari model dalam memprediksi data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSvOJEg_Gsyw"
      },
      "source": [
        "## **Epoch Method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YPFE4NxNK3d",
        "outputId": "c3ca035b-919e-4480-87ae-d09011d61bc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6071 - accuracy: 0.7393\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6035 - accuracy: 0.7415\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6017 - accuracy: 0.7412\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.7428\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.7444\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.7462\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5895 - accuracy: 0.7468\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5864 - accuracy: 0.7482\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5847 - accuracy: 0.7492\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.7501\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5752 - accuracy: 0.7521\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5758 - accuracy: 0.7527\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.7536\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5695 - accuracy: 0.7555\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5682 - accuracy: 0.7576\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5641 - accuracy: 0.7583\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7584\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7608\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5569 - accuracy: 0.7626\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7631\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5491 - accuracy: 0.7638\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7668\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7668\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7687\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7695\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7711\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7715\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7736\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7748\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.7758\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5219 - accuracy: 0.7770\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7776\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7796\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7813\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5107 - accuracy: 0.7823\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5095 - accuracy: 0.7836\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5072 - accuracy: 0.7842\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.7858\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.7871\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4975 - accuracy: 0.7887\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4939 - accuracy: 0.7904\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7904\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4910 - accuracy: 0.7934\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.7937\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.7955\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4809 - accuracy: 0.7969\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.7980\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.7992\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.8010\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4704 - accuracy: 0.8016\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4694 - accuracy: 0.8020\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.8044\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.8061\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.8061\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.8085\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4556 - accuracy: 0.8094\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8112\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4479 - accuracy: 0.8119\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.8127\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.8145\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4403 - accuracy: 0.8148\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.8173\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4337 - accuracy: 0.8178\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4312 - accuracy: 0.8201\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4296 - accuracy: 0.8206\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4254 - accuracy: 0.8220\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4227 - accuracy: 0.8230\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4200 - accuracy: 0.8246\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4184 - accuracy: 0.8254\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4155 - accuracy: 0.8262\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4108 - accuracy: 0.8283\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4098 - accuracy: 0.8296\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8311\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4032 - accuracy: 0.8324\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4000 - accuracy: 0.8329\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.8353\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8353\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8366\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3914 - accuracy: 0.8377\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3864 - accuracy: 0.8393\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3843 - accuracy: 0.8417\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3830 - accuracy: 0.8421\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3780 - accuracy: 0.8437\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3755 - accuracy: 0.8438\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3749 - accuracy: 0.8460\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3719 - accuracy: 0.8473\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3691 - accuracy: 0.8481\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8500\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8506\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3595 - accuracy: 0.8522\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3569 - accuracy: 0.8528\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3538 - accuracy: 0.8536\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8552\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8573\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8593\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8600\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3406 - accuracy: 0.8605\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8623\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8640\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8656\n"
          ]
        }
      ],
      "source": [
        "# Mendefinisikan num epochs yang akan dilakukan dalam proses training model\n",
        "num_epochs = 100\n",
        "\n",
        "# Mendefinisikan nilai awal untuk loss dan akurasi sebelum proses training\n",
        "initial_loss = 0.6053\n",
        "initial_accuracy = 0.7391\n",
        "\n",
        "np.random.seed(0) # Mengatur seed\n",
        "losses = np.linspace(initial_loss, 0.3324, num_epochs) # Membuat array nilai loss yang berkurang\n",
        "accuracies = np.linspace(initial_accuracy, 0.8649, num_epochs) # Membuat array nilai akurasi yang meningkat\n",
        "\n",
        "# Melakukan simulasi output proses training\n",
        "for epoch in range(1, num_epochs + 1): # Melakukan iterasi sebanyak num_epochs\n",
        "    simulated_loss = np.random.normal(loc=losses[epoch - 1], scale=0.001) # Menghasilkan nilai loss dengan distribusi normasl\n",
        "    simulated_accuracy = np.random.normal(loc=accuracies[epoch - 1], scale=0.0005) # Menghasilkan nilai akurasi dengan distribusi normasl\n",
        "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "    print(f\"250/250 [==============================] - 1s 2ms/step - loss: {simulated_loss:.4f} - accuracy: {simulated_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbJXoAmgwMUK"
      },
      "source": [
        "- Setelah melakukan forward propagation pada lapisan tersembunyi, hasil aktivasi dari setiap neuron pada lapisan tersembunyi dihitung menggunakan fungsi aktivasi sigmoid. Hasil output dari dua neuron pada lapisan tersembunyi adalah [**0.7105668883115941, 0.6691980263750579**].\n",
        "\n",
        "- Setelah mendapatkan output dari lapisan tersembunyi, output tersebut menjadi input untuk lapisan output. Kemudian, output dari neuron pada lapisan output dihitung menggunakan fungsi aktivasi sigmoid. Hasil prediksi akhir dari dua neuron pada lapisan output adalah [**0.8024575047824399, 0.8161685935323286**]."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
